{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #for OS utilities\n",
    "from PIL import Image #import image\n",
    "import math\n",
    "import pickle #Save and Load Data\n",
    "import numpy as np # for linear algebra and matrices operations\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread #For reading an image\n",
    "import matplotlib.pyplot as plt # For Plotting an images\n",
    "import gc # Garbage Collection for optimized memory allocation\n",
    "import sklearn\n",
    "gc.enable() # memory is tight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_label_dictionary = {\n",
    "0:  \"Nucleoplasm\", \n",
    "1:  \"Nuclear membrane\",   \n",
    "2:  \"Nucleoli\",   \n",
    "3:  \"Nucleoli fibrillar center\" ,  \n",
    "4:  \"Nuclear speckles\"   ,\n",
    "5:  \"Nuclear bodies\"   ,\n",
    "6:  \"Endoplasmic reticulum\",   \n",
    "7:  \"Golgi apparatus\"   ,\n",
    "8:  \"Peroxisomes\"   ,\n",
    "9:  \"Endosomes\"   ,\n",
    "10:  \"Lysosomes\"   ,\n",
    "11:  \"Intermediate filaments\",   \n",
    "12:  \"Actin filaments\"   ,\n",
    "13:  \"Focal adhesion sites\",   \n",
    "14:  \"Microtubules\"   ,\n",
    "15:  \"Microtubule ends\",   \n",
    "16:  \"Cytokinetic bridge\",   \n",
    "17:  \"Mitotic spindle\"   ,\n",
    "18:  \"Microtubule organizing center\" ,  \n",
    "19:  \"Centrosome\"   ,\n",
    "20:  \"Lipid droplets\",   \n",
    "21:  \"Plasma membrane\",   \n",
    "22:  \"Cell junctions\"  , \n",
    "23:  \"Mitochondria\"   ,\n",
    "24:  \"Aggresome\"   ,\n",
    "25:  \"Cytosol\",\n",
    "26:  \"Cytoplasmic bodies\",   \n",
    "27:  \"Rods & rings\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataframe = pd.read_csv('train.csv') #Create a Data Frame to store the images along with the labels\n",
    "print(image_dataframe.head())\n",
    "print('The shape of datatframe is: ',image_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_combination_dataframe = image_dataframe['Target'].value_counts()\n",
    "print(count_combination_dataframe.head())\n",
    "print(len(image_dataframe['Target'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "encoder = MultiLabelBinarizer()\n",
    "encoder.fit_transform([(0,), (1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,), (11,), (12,), (13,), (14,), (15,), (16,),(17,), (18,), (19,), (20,), (21,), (22,), (23,), (24,), (25,), (26,),(27,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.transform([(22,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "samples = list(zip(image_dataframe['Id'],image_dataframe['Target']))\n",
    "train_samples, validation_samples = train_test_split(samples,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data,batch_size=8):\n",
    "    images_path_length = len(data)\n",
    "    while 1:\n",
    "        for off in range(0,images_path_length,batch_size):\n",
    "            images_list = data[off:off+batch_size]\n",
    "            rgb_arr=[]\n",
    "            label=[]\n",
    "            for j in images_list:\n",
    "                red=[]\n",
    "                green=[]\n",
    "                blue=[]\n",
    "                yellow=[]\n",
    "                red = np.array(Image.open(\"train/\"+j[0]+\"_red.png\").convert(\"L\"))/255\n",
    "                green = np.array(Image.open(\"train/\"+j[0]+\"_green.png\").convert(\"L\"))/255\n",
    "                blue = np.array(Image.open(\"train/\"+j[0]+\"_blue.png\").convert(\"L\"))/255\n",
    "                yellow = np.array(Image.open(\"train/\"+j[0]+\"_yellow.png\").convert(\"L\"))/255\n",
    "                rgb_arr.append(np.stack([red/2+yellow/2,green/2+yellow/2,blue], -1))\n",
    "                label.append(encoder.transform([tuple(map(int,j[1].split()))]))\n",
    "            yield np.array(rgb_arr),np.array(label).reshape(len(label),28)#,batch_size,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_gen = generator(train_samples)\n",
    "val_images_gen = generator(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "\n",
    "model = InceptionV3(include_top = True, weights = None, classes=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "x = model.layers[-1].output\n",
    "x = Dense(28, activation='sigmoid', name='predictions')(x)\n",
    "train_model = Model(input=model.input,output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "train_model.fit_generator(train_images_gen,epochs=2,verbose=1,steps_per_epoch=len(train_samples)/8, validation_data=val_images_gen,validation_steps=len(validation_samples)/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.save_weights('Human_atlas.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_model.history.history['loss'])\n",
    "plt.plot(train_model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.load_weights('Human_atlas.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_generator(data,batch_size=8):\n",
    "    images_path_length = len(data)\n",
    "    while 1:\n",
    "        for off in range(0,images_path_length,batch_size):\n",
    "            images_list = data[off:off+batch_size]\n",
    "            rgb_arr=[]\n",
    "            #label=[]\n",
    "            for j in images_list:\n",
    "                red=[]\n",
    "                green=[]\n",
    "                blue=[]\n",
    "                yellow=[]\n",
    "                red = np.array(Image.open(\"test/\"+j[0]+\"_red.png\").convert(\"L\"))/255\n",
    "                green = np.array(Image.open(\"test/\"+j[0]+\"_green.png\").convert(\"L\"))/255\n",
    "                blue = np.array(Image.open(\"test/\"+j[0]+\"_blue.png\").convert(\"L\"))/255\n",
    "                yellow = np.array(Image.open(\"test/\"+j[0]+\"_yellow.png\").convert(\"L\"))/255\n",
    "                rgb_arr.append(np.stack([red/2+yellow/2,green/2+yellow/2,blue], -1))\n",
    "                #label.append(encoder.transform([tuple(map(int,j[1].split()))]))\n",
    "            yield np.array(rgb_arr)#,np.array(label).reshape(len(label),28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = list(zip(test_df['Id']))\n",
    "test_images_gen = predict_generator(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_model.predict_generator(test_images_gen,steps=len(test_samples)/8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in results:\n",
    "    label_predict=np.arange(28)[i >=0.2]\n",
    "    predictions.append(' '.join(str(l) for l in label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Predicted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_arr_check=[]\n",
    "red_check = np.array(Image.open(\"train/\"+'008761b4-bbad-11e8-b2ba-ac1f6b6435d0'+\"_red.png\").convert(\"L\"))/255\n",
    "green_check = np.array(Image.open(\"train/\"+'008761b4-bbad-11e8-b2ba-ac1f6b6435d0'+\"_green.png\").convert(\"L\"))/255\n",
    "blue_check = np.array(Image.open(\"train/\"+'008761b4-bbad-11e8-b2ba-ac1f6b6435d0'+\"_blue.png\").convert(\"L\"))/255\n",
    "yellow_check = np.array(Image.open(\"train/\"+'008761b4-bbad-11e8-b2ba-ac1f6b6435d0'+\"_yellow.png\").convert(\"L\"))/255\n",
    "rgb_arr_check.append(np.stack([red_check/2+yellow_check/2,green_check/2+yellow_check/2,blue_check], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=train_model.predict(np.array(rgb_arr_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp)\n",
    "np.arange(28)[tmp[0] >=0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(0,math.ceil(len(image_dataframe['Id'])/32)):\n",
    "    values=next(train_images_gen)\n",
    "    print(values[0].shape)\n",
    "    #with open('rgb_images_1.pkl','ab') as f:\n",
    "        #pickle.dump(values[0],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('rgb_norm.pkl','wb') as f:\n",
    "    pickle.dump(rgb_arr,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rgb_arr=[]\n",
    "for i in range(0,math.ceil(len(image_dataframe['Id'])/32)):\n",
    "    values=next(images_gen)\n",
    "    for j in range(0,32):\n",
    "        rgb_arr.append(np.stack([values[0][j]/2+values[3][j]/2,values[1][j]/2+values[3][j]/2,values[2][j]], -1))\n",
    "    print(len(rgb_arr),rgb_arr[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
